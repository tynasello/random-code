{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0sxXYk0M_oCG",
   "metadata": {
    "id": "0sxXYk0M_oCG"
   },
   "source": [
    "The goal is to predict the nationality of a name using a vanilla RNN.\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QN-48vVd6tKt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2860,
     "status": "ok",
     "timestamp": 1661547048568,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "QN-48vVd6tKt",
    "outputId": "37e6ca4d-ef35-4474-964d-7719dbdbdaef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd98d08-1988-4aa9-a497-cdd5cb15dd86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:06.693538Z",
     "iopub.status.busy": "2022-08-26T18:20:06.692968Z",
     "iopub.status.idle": "2022-08-26T18:20:07.957146Z",
     "shell.execute_reply": "2022-08-26T18:20:07.955473Z",
     "shell.execute_reply.started": "2022-08-26T18:20:06.693426Z"
    },
    "id": "2dd98d08-1988-4aa9-a497-cdd5cb15dd86"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ee5d4-7721-43f1-b31f-5c79732cfdb4",
   "metadata": {
    "id": "f13ee5d4-7721-43f1-b31f-5c79732cfdb4"
   },
   "source": [
    "Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8408374-2724-4e64-9466-19a207644468",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-23T22:17:10.451867Z",
     "iopub.status.busy": "2022-08-23T22:17:10.451520Z",
     "iopub.status.idle": "2022-08-23T22:17:12.800723Z",
     "shell.execute_reply": "2022-08-23T22:17:12.799038Z",
     "shell.execute_reply.started": "2022-08-23T22:17:10.451841Z"
    },
    "executionInfo": {
     "elapsed": 3350,
     "status": "ok",
     "timestamp": 1661547060183,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "b8408374-2724-4e64-9466-19a207644468",
    "outputId": "882a9642-379a-419f-81b2-6c8329e4af5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2814k  100 2814k    0     0  1134k      0  0:00:02  0:00:02 --:--:-- 1134k\n",
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/eng-fra.txt        \n",
      "   creating: data/names/\n",
      "  inflating: data/names/Arabic.txt   \n",
      "  inflating: data/names/Chinese.txt  \n",
      "  inflating: data/names/Czech.txt    \n",
      "  inflating: data/names/Dutch.txt    \n",
      "  inflating: data/names/English.txt  \n",
      "  inflating: data/names/French.txt   \n",
      "  inflating: data/names/German.txt   \n",
      "  inflating: data/names/Greek.txt    \n",
      "  inflating: data/names/Irish.txt    \n",
      "  inflating: data/names/Italian.txt  \n",
      "  inflating: data/names/Japanese.txt  \n",
      "  inflating: data/names/Korean.txt   \n",
      "  inflating: data/names/Polish.txt   \n",
      "  inflating: data/names/Portuguese.txt  \n",
      "  inflating: data/names/Russian.txt  \n",
      "  inflating: data/names/Scottish.txt  \n",
      "  inflating: data/names/Spanish.txt  \n",
      "  inflating: data/names/Vietnamese.txt  \n"
     ]
    }
   ],
   "source": [
    "!curl -O https://download.pytorch.org/tutorial/data.zip; unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c9553-527f-4f7e-b59f-7214385d5c41",
   "metadata": {
    "id": "9d4c9553-527f-4f7e-b59f-7214385d5c41"
   },
   "source": [
    "Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b9586-a0ee-468d-9eb5-ab4db7993fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:07.960113Z",
     "iopub.status.busy": "2022-08-26T18:20:07.959546Z",
     "iopub.status.idle": "2022-08-26T18:20:07.967803Z",
     "shell.execute_reply": "2022-08-26T18:20:07.966255Z",
     "shell.execute_reply.started": "2022-08-26T18:20:07.960073Z"
    },
    "id": "e80b9586-a0ee-468d-9eb5-ab4db7993fc3"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "def to_t(tensor):\n",
    "    #convert tensor to gpu if available\n",
    "    return tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934163f-93cd-4379-b7c8-08bae0e51324",
   "metadata": {
    "id": "6934163f-93cd-4379-b7c8-08bae0e51324"
   },
   "source": [
    "Language to id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e475d3b-95af-4a15-b890-50e36c9f3df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:07.970253Z",
     "iopub.status.busy": "2022-08-26T18:20:07.969898Z",
     "iopub.status.idle": "2022-08-26T18:20:10.152505Z",
     "shell.execute_reply": "2022-08-26T18:20:10.150876Z",
     "shell.execute_reply.started": "2022-08-26T18:20:07.970223Z"
    },
    "id": "9e475d3b-95af-4a15-b890-50e36c9f3df2"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree('data/names/.ipynb_checkpoints')\n",
    "filenames = [f for f in os.listdir('data/names')]\n",
    "    \n",
    "lang_to_id = {\n",
    "    language.split('.')[0]: to_t(torch.tensor(i)) for i, language in enumerate(filenames)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0e1d5-6a3e-4292-88a5-599813012b5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:10.155913Z",
     "iopub.status.busy": "2022-08-26T18:20:10.155600Z",
     "iopub.status.idle": "2022-08-26T18:20:10.176801Z",
     "shell.execute_reply": "2022-08-26T18:20:10.175378Z",
     "shell.execute_reply.started": "2022-08-26T18:20:10.155913Z"
    },
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1661547165909,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "15f0e1d5-6a3e-4292-88a5-599813012b5b",
    "outputId": "5d89575d-e8a4-4b33-c351-582824768c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Portuguese': tensor(0, device='cuda:0'), 'Scottish': tensor(1, device='cuda:0'), 'German': tensor(2, device='cuda:0'), 'Irish': tensor(3, device='cuda:0'), 'Arabic': tensor(4, device='cuda:0'), 'Vietnamese': tensor(5, device='cuda:0'), 'Spanish': tensor(6, device='cuda:0'), 'Japanese': tensor(7, device='cuda:0'), 'Dutch': tensor(8, device='cuda:0'), 'French': tensor(9, device='cuda:0'), 'Czech': tensor(10, device='cuda:0'), 'English': tensor(11, device='cuda:0'), 'Russian': tensor(12, device='cuda:0'), 'Greek': tensor(13, device='cuda:0'), 'Chinese': tensor(14, device='cuda:0'), 'Korean': tensor(15, device='cuda:0'), 'Polish': tensor(16, device='cuda:0'), 'Italian': tensor(17, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(lang_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39190ef4-d729-41f8-8ab4-3a746e3dda02",
   "metadata": {
    "id": "39190ef4-d729-41f8-8ab4-3a746e3dda02"
   },
   "source": [
    "Character to id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706ee1c-ca88-4bc0-b738-bddd342c390c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:10.178761Z",
     "iopub.status.busy": "2022-08-26T18:20:10.178456Z",
     "iopub.status.idle": "2022-08-26T18:20:10.189828Z",
     "shell.execute_reply": "2022-08-26T18:20:10.187237Z",
     "shell.execute_reply.started": "2022-08-26T18:20:10.178723Z"
    },
    "id": "e706ee1c-ca88-4bc0-b738-bddd342c390c"
   },
   "outputs": [],
   "source": [
    "char_to_id = {\n",
    "    char: i for i, char in enumerate(string.ascii_lowercase + \" -'\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c4daf-bd45-455b-ae11-a22644689d10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:10.191724Z",
     "iopub.status.busy": "2022-08-26T18:20:10.191317Z",
     "iopub.status.idle": "2022-08-26T18:20:10.202011Z",
     "shell.execute_reply": "2022-08-26T18:20:10.200740Z",
     "shell.execute_reply.started": "2022-08-26T18:20:10.191724Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1661547172740,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "881c4daf-bd45-455b-ae11-a22644689d10",
    "outputId": "ad221c52-fba4-4f01-d0c1-842d6e6c5fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, ' ': 26, '-': 27, \"'\": 28}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a4097-7767-4845-83c4-b958dd07cd95",
   "metadata": {
    "id": "3f1a4097-7767-4845-83c4-b958dd07cd95"
   },
   "source": [
    "Functions to convert names and languages to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3598383-7bf9-4f43-8bec-a1ac70bc5b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:10.204681Z",
     "iopub.status.busy": "2022-08-26T18:20:10.203856Z",
     "iopub.status.idle": "2022-08-26T18:20:10.213474Z",
     "shell.execute_reply": "2022-08-26T18:20:10.211978Z",
     "shell.execute_reply.started": "2022-08-26T18:20:10.204299Z"
    },
    "id": "e3598383-7bf9-4f43-8bec-a1ac70bc5b20"
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[1/,:ÃŸ]')\n",
    "\n",
    "def name_to_tensor(name):\n",
    "    name_tensor = to_t(torch.zeros(len(name), 1, len(char_to_id)))\n",
    "    # convert text to unicode, make lowercase and remove any symbols that shouldn't exist\n",
    "    name = unidecode.unidecode(regex.sub('', name.lower()))\n",
    "    \n",
    "    # one hot encode tensor for inputted name\n",
    "    for i, char in enumerate(name):\n",
    "        name_tensor[i][0][char_to_id[char]] = 1\n",
    "    \n",
    "    return name_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13160f-1458-4693-a1d2-afbaf699f800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:10.219032Z",
     "iopub.status.busy": "2022-08-26T18:20:10.215085Z",
     "iopub.status.idle": "2022-08-26T18:20:10.227364Z",
     "shell.execute_reply": "2022-08-26T18:20:10.225867Z",
     "shell.execute_reply.started": "2022-08-26T18:20:10.218994Z"
    },
    "id": "cf13160f-1458-4693-a1d2-afbaf699f800"
   },
   "outputs": [],
   "source": [
    "def lang_to_tensor(lang):\n",
    "    # one hot encode tensor for inputted language\n",
    "    lang_tensor = to_t(torch.zeros(len(lang_to_id)))\n",
    "    lang_tensor[lang_to_id[lang]] = 1\n",
    "    \n",
    "    return lang_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdceb968-70be-46e4-bde8-f979b365ae85",
   "metadata": {
    "id": "bdceb968-70be-46e4-bde8-f979b365ae85"
   },
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db7b1d-c444-4bca-a7b0-8790f7fe14df",
   "metadata": {
    "id": "56db7b1d-c444-4bca-a7b0-8790f7fe14df"
   },
   "source": [
    "Loading names and languages into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf2e8e-011b-48cf-89dc-4282858b0beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:10.229019Z",
     "iopub.status.busy": "2022-08-26T18:20:10.228618Z",
     "iopub.status.idle": "2022-08-26T18:20:16.887990Z",
     "shell.execute_reply": "2022-08-26T18:20:16.886897Z",
     "shell.execute_reply.started": "2022-08-26T18:20:10.228984Z"
    },
    "id": "e2bf2e8e-011b-48cf-89dc-4282858b0beb"
   },
   "outputs": [],
   "source": [
    "# one hot encoded tensors of names\n",
    "x_names = []\n",
    "# one hot encoded tensors of corresponding languages\n",
    "# language at index i in y_langs is the language of the name at index i in x_names\n",
    "y_langs = []\n",
    "\n",
    "for filename in filenames:\n",
    "    with open('data/names/'+ filename) as f:\n",
    "        names = f.read().split()\n",
    "\n",
    "        for name in names:\n",
    "            x_names.append(name_to_tensor(name))\n",
    "            y_langs.append(lang_to_tensor(filename.split('.')[0]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8328f-4238-49c9-8463-51f28ff5b29a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:16.891770Z",
     "iopub.status.busy": "2022-08-26T18:20:16.891409Z",
     "iopub.status.idle": "2022-08-26T18:20:16.900044Z",
     "shell.execute_reply": "2022-08-26T18:20:16.898201Z",
     "shell.execute_reply.started": "2022-08-26T18:20:16.891727Z"
    },
    "id": "21d8328f-4238-49c9-8463-51f28ff5b29a"
   },
   "outputs": [],
   "source": [
    "class NameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, names, langs):\n",
    "        self.names = names\n",
    "        self.langs = langs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        item = {\n",
    "            'name': self.names[i],\n",
    "            'lang': self.langs[i]\n",
    "        }\n",
    "        return item\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89beac-4330-4b53-af22-9b35c564593a",
   "metadata": {
    "id": "ca89beac-4330-4b53-af22-9b35c564593a"
   },
   "source": [
    "Creating dataset and splitting into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10df4e-960e-4392-9e9b-12bab3aa3e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:16.902789Z",
     "iopub.status.busy": "2022-08-26T18:20:16.902034Z",
     "iopub.status.idle": "2022-08-26T18:20:16.913560Z",
     "shell.execute_reply": "2022-08-26T18:20:16.912246Z",
     "shell.execute_reply.started": "2022-08-26T18:20:16.902734Z"
    },
    "id": "8b10df4e-960e-4392-9e9b-12bab3aa3e6b"
   },
   "outputs": [],
   "source": [
    "dataset = NameDataset(x_names, y_langs)\n",
    "\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc173cd-6d0c-4942-ab74-f55c29e6bfef",
   "metadata": {
    "id": "bfc173cd-6d0c-4942-ab74-f55c29e6bfef"
   },
   "source": [
    "Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30384c6a-0866-4dea-8935-ea4c304a1c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:20:16.915106Z",
     "iopub.status.busy": "2022-08-26T18:20:16.914781Z",
     "iopub.status.idle": "2022-08-26T18:20:16.922308Z",
     "shell.execute_reply": "2022-08-26T18:20:16.920692Z",
     "shell.execute_reply.started": "2022-08-26T18:20:16.915079Z"
    },
    "id": "30384c6a-0866-4dea-8935-ea4c304a1c2e"
   },
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "data_loaders = {'train': train_data_loader, 'test': test_data_loader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf893fc-09f0-4d7b-ba65-09d57d134ddb",
   "metadata": {
    "id": "cdf893fc-09f0-4d7b-ba65-09d57d134ddb"
   },
   "source": [
    "### Nationality Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1415150-b8d6-4711-9217-93a51815ca41",
   "metadata": {
    "id": "a1415150-b8d6-4711-9217-93a51815ca41"
   },
   "source": [
    "Vanilla RNN model architecture from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1839c-7db7-46a7-b984-62fec94e5261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T18:32:39.501925Z",
     "iopub.status.busy": "2022-08-26T18:32:39.501421Z",
     "iopub.status.idle": "2022-08-26T18:32:39.513013Z",
     "shell.execute_reply": "2022-08-26T18:32:39.511371Z",
     "shell.execute_reply.started": "2022-08-26T18:32:39.501886Z"
    },
    "id": "9bf1839c-7db7-46a7-b984-62fec94e5261"
   },
   "outputs": [],
   "source": [
    "class NationalityModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NationalityModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_to_hidden = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_to_output = torch.nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = self.input_to_hidden(combined)\n",
    "        output = self.input_to_output(combined)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return to_t(torch.zeros(1, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f296541-638d-4203-9370-75ce6295b370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T20:13:26.710250Z",
     "iopub.status.busy": "2022-08-26T20:13:26.709458Z",
     "iopub.status.idle": "2022-08-26T20:13:26.720149Z",
     "shell.execute_reply": "2022-08-26T20:13:26.718827Z",
     "shell.execute_reply.started": "2022-08-26T20:13:26.710158Z"
    },
    "id": "1f296541-638d-4203-9370-75ce6295b370"
   },
   "outputs": [],
   "source": [
    "model = NationalityModel(len(char_to_id), 128, len(lang_to_id))\n",
    "# model to gpu if available\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbd09c-e4bf-4ba3-80b1-b00c6966a367",
   "metadata": {
    "id": "b9dbd09c-e4bf-4ba3-80b1-b00c6966a367"
   },
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c89e0e-7e21-4ca2-af0e-639db6b0cbe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-26T20:18:09.438238Z",
     "iopub.status.busy": "2022-08-26T20:18:09.437752Z"
    },
    "executionInfo": {
     "elapsed": 41736,
     "status": "ok",
     "timestamp": 1661547573205,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "33c89e0e-7e21-4ca2-af0e-639db6b0cbe4",
    "outputId": "9cf5ce57-e730-4bb5-a10d-894f22e7f6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.3329\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, train_data in enumerate(data_loaders['train']):\n",
    "        hidden_state = model.init_hidden()\n",
    "        \n",
    "        for name in train_data['name']:\n",
    "            # zero gradients when feeding new word to model\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for char in name:\n",
    "                # feed each char of the name and the current hidden state to model\n",
    "                output, hidden_state = model(char, hidden_state)\n",
    "                \n",
    "            # calculate loss using cross entropy loss function\n",
    "            loss = criterion(output, train_data['lang'])\n",
    "\n",
    "            # caculate gradients of loss function\n",
    "            loss.backward()\n",
    "            # step model using calculated gradients to minimize loss\n",
    "            optimizer.step()\n",
    "        \n",
    "            \n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "        f\"Loss: {loss.item():.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d8cd3-a472-4525-a227-d117c678b7d6",
   "metadata": {
    "id": "b37d8cd3-a472-4525-a227-d117c678b7d6"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae10b1c-d5bc-42aa-8f56-2afe9f50eb99",
   "metadata": {
    "id": "8ae10b1c-d5bc-42aa-8f56-2afe9f50eb99"
   },
   "source": [
    "Testing model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88603df-0d14-4546-913d-5a5826892b04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-26T20:24:31.545677Z",
     "iopub.status.busy": "2022-08-26T20:24:31.544479Z",
     "iopub.status.idle": "2022-08-26T20:24:34.802483Z",
     "shell.execute_reply": "2022-08-26T20:24:34.800841Z",
     "shell.execute_reply.started": "2022-08-26T20:24:31.545614Z"
    },
    "executionInfo": {
     "elapsed": 2402,
     "status": "ok",
     "timestamp": 1661548155685,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "a88603df-0d14-4546-913d-5a5826892b04",
    "outputId": "70d7be3d-ddd2-4977-f86a-5bcda24921ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.6974%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for train_data in data_loaders['test']:\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in train_data['name'][0]:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        pred = torch.argmax(output).item()\n",
    "        num_correct += bool(pred == torch.argmax(train_data['lang']).item())\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf470e42-3a66-4a65-8d59-6d94df2afb20",
   "metadata": {
    "id": "bf470e42-3a66-4a65-8d59-6d94df2afb20"
   },
   "source": [
    "The model is overfitting. I think this is because of the small ammount of data being used in training, as well as the fact that the number of names are unevenly distributed among languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18fd6f-90a1-4901-aeb7-ffb8104f9a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T20:24:36.895499Z",
     "iopub.status.busy": "2022-08-26T20:24:36.894962Z",
     "iopub.status.idle": "2022-08-26T20:24:36.903826Z",
     "shell.execute_reply": "2022-08-26T20:24:36.902355Z",
     "shell.execute_reply.started": "2022-08-26T20:24:36.895450Z"
    },
    "id": "9b18fd6f-90a1-4901-aeb7-ffb8104f9a17"
   },
   "outputs": [],
   "source": [
    "def predict_nationality(name):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name_to_tensor(name):\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "\n",
    "    return(list(lang_to_id.keys())[list(lang_to_id.values()).index(torch.argmax(output).item())])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2bd86-4b2e-45f9-a5e2-af034019ffd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-08-26T20:26:58.155601Z",
     "iopub.status.busy": "2022-08-26T20:26:58.155065Z",
     "iopub.status.idle": "2022-08-26T20:26:58.177458Z",
     "shell.execute_reply": "2022-08-26T20:26:58.172634Z",
     "shell.execute_reply.started": "2022-08-26T20:26:58.155571Z"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1661548174276,
     "user": {
      "displayName": "Ty N",
      "userId": "11735844546653177082"
     },
     "user_tz": 240
    },
    "id": "15c2bd86-4b2e-45f9-a5e2-af034019ffd3",
    "outputId": "ea66d1d2-be12-4ec7-f268-b9cb8cd6262d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian\n",
      "Arabic\n",
      "Chinese\n"
     ]
    }
   ],
   "source": [
    "print(predict_nationality('Lucchese'))\n",
    "print(predict_nationality('Muhammad'))\n",
    "print(predict_nationality('Xiu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TNHaJip6_RcX",
   "metadata": {
    "id": "TNHaJip6_RcX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vanilla-rnn.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
