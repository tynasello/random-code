{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A statistical model used for classification. In Logistic regression we are determining the best predicted weights for a logit function that make the logistic regression function's (sigmoid function of the logit) outputs closest to the real outputs. \n",
    "\n",
    "In binary classification, the logistic regression function's outputs can be viewed as the predicted probability that a given input is classified as a 1. We get the best weights through maximizing the log-likelihood function across all observations.prediction's below 0.5 are classified as 0, and over 0.5 as 1.\n",
    "\n",
    "https://realpython.com/logistic-regression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll classify handwritten digits from an sklearn dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "x, y = load_digits(return_X_y=True)\n",
    "\n",
    "# split data into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  9., 11.,  0.,  0.,  0.,  0.,  0.,  2., 15.,  8.,\n",
       "         0.,  0.,  0.,  0.,  0., 11., 15.,  1.,  3.,  8.,  0.,  0.,  6.,\n",
       "        16.,  4.,  0., 14., 12.,  0.,  0., 12., 16.,  4., 11., 16.,  5.,\n",
       "         0.,  0.,  9., 16., 16., 16., 11.,  0.,  0.,  0.,  0.,  6., 11.,\n",
       "        16.,  7.,  0.,  0.,  0.,  0.,  0., 10., 16.,  4.,  0.,  0.]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data-science-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e955d9f5300169bbbf016d1b1b6aa83fb81dee4a3f4ac144c12d1d677128a7e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
